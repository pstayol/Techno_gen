{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='6'>**WGAN(with clipping) Training**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from PIL import ImageFile\n",
    "%matplotlib inline\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "manualSeed = 1000\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ndf * 2, affine=True),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(ndf*2, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ndf * 8,affine=True),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d( nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "#parameters\n",
    "########################\n",
    "ndf= 64\n",
    "ngf= 64\n",
    "nc= 3\n",
    "ngpu= 1\n",
    "epochs= 5\n",
    "nz= 100\n",
    "lr1 = 0.00002\n",
    "lr2 = 0.00002\n",
    "imsize= 64\n",
    "batch_size= 64\n",
    "wr= 2\n",
    "########################\n",
    "#part of dataset 60k samples out of ~ 260k\n",
    "data_path= \"/home/pstayol/Desktop/dataset/datas\"\n",
    "datas= data.ImageFolder(root=data_path,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(imsize),\n",
    "                               transforms.CenterCrop(imsize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "writer_real = SummaryWriter(f\"logs/real5\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake5\")\n",
    "disc= Discriminator(ngpu).to(device)\n",
    "gen= Generator(ngpu).to(device)\n",
    "disc.apply(weights_init)\n",
    "gen.apply(weights_init)\n",
    "optm_gen= optim.RMSprop(gen.parameters(), lr=lr1)\n",
    "optm_disc= optim.RMSprop(disc.parameters(), lr=lr2)\n",
    "real_l= 1\n",
    "fake_l= 0\n",
    "gen_loss= []\n",
    "disc_loss= []\n",
    "img_list= []\n",
    "step= 0\n",
    "eval_interval= 10\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "dataloader = torch.utils.data.DataLoader(datas, batch_size=batch_size,shuffle=True, num_workers=wr)\n",
    "wclip= 0.01\n",
    "disciter=5   \n",
    "#Training Loop\n",
    "for epoch in range(epochs):\n",
    "    for i, real_data in enumerate(dataloader, 0):\n",
    "        # Train Discriminator\n",
    "        disc.zero_grad()\n",
    "        # Train with real data\n",
    "        real = real_data[0].to(device)\n",
    "        batch_size = real.size(0)\n",
    "        for _ in range(disciter):\n",
    "            noise = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            disc_real = disc(real).reshape(-1)\n",
    "            disc_fake = disc(fake).reshape(-1)\n",
    "            loss_disc = -(torch.mean(disc_real) - torch.mean(disc_fake))\n",
    "            disc.zero_grad()\n",
    "            loss_disc.backward(retain_graph=True)\n",
    "            optm_disc.step()\n",
    "\n",
    "            # clip critic weights between -0.01, 0.01\n",
    "            for p in disc.parameters():\n",
    "                p.data.clamp_(-wclip, wclip)\n",
    "        # Train Generator\n",
    "        gen_fake = disc(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        optm_gen.step()\n",
    "        # Record Losses\n",
    "        gen_loss.append(loss_gen.item())\n",
    "        disc_loss.append(loss_disc.item())\n",
    "        if (epoch == epochs-1) and (i == len(datas)-1):\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Batch [{i}/{len(dataloader)}]\"\n",
    "                  f\"Discriminator Loss: {loss_disc.item():.4f}, \"\n",
    "                  f\"Generator Loss: {loss_gen.item():.4f}\")\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                real = real_data[0]\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "        step=step+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='6'>**Visualize Loss**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Generator and Discriminator Loss During Training 5 epochs and 60k samples\")\n",
    "plt.plot(gen_loss,label=\"G\")\n",
    "plt.plot(disc_loss,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='6'>**Save Model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen,'/path/wgan5epclip.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
